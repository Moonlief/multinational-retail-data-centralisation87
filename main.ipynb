{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials loaded sucessfully!!\n",
      "Connection successful!\n"
     ]
    }
   ],
   "source": [
    "#Importing modules\n",
    "\n",
    "import pandas as pd\n",
    "import tabula\n",
    "import yaml\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy import inspect\n",
    "import requests\n",
    "from database_utils import DatabaseConnector\n",
    "from data_extraction import DataExtractor\n",
    "from data_cleaning import DataCleaning\n",
    "import importlib\n",
    "import json\n",
    "import boto3\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "#starting local database\n",
    "\n",
    "#read creds\n",
    "uploader = DatabaseConnector()\n",
    "ml_yaml = 'ml_dbs.yaml'\n",
    "uploader.read_db_creds(ml_yaml)\n",
    "\n",
    "# initialising and returning an sqlalchemy database engine.\n",
    "\n",
    "uploading = uploader.init_db_engine_postgresql()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RDS Database ETL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Getting data from the RDS database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credentials loaded sucessfully!!\n",
      "Connection successful!\n",
      "Tables in the database: ['legacy_store_details', 'dim_card_details', 'legacy_users', 'orders_table']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## read credentials\n",
    "connector_rds = DatabaseConnector()\n",
    "ai_core_yaml = 'db_creds.yaml'\n",
    "connector_rds.read_db_creds(ai_core_yaml)\n",
    "\n",
    "## initialising and returning an sqlalchemy database engine.\n",
    "connection_rds = connector_rds.init_db_engine()\n",
    "\n",
    "## Reading the data from the RDS database\n",
    "connector_tables_rds = connector_rds.list_db_tables()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extracting the table to a pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   index first_name last_name date_of_birth                    company  \\\n",
      "0      0   Sigfried     Noack    1990-09-30         Heydrich Junitz KG   \n",
      "1      1        Guy     Allen    1940-12-01                    Fox Ltd   \n",
      "2      2      Harry  Lawrence    1995-08-02  Johnson, Jones and Harris   \n",
      "3      3     Darren   Hussain    1972-09-23                Wheeler LLC   \n",
      "4      4      Garry     Stone    1952-12-20                 Warner Inc   \n",
      "\n",
      "                  email_address  \\\n",
      "0             rudi79@winkler.de   \n",
      "1  rhodesclifford@henderson.com   \n",
      "2  glen98@bryant-marshall.co.uk   \n",
      "3    daniellebryan@thompson.org   \n",
      "4       billy14@long-warren.com   \n",
      "\n",
      "                                             address         country  \\\n",
      "0                       Zimmerstr. 1/0\\n59015 Gießen         Germany   \n",
      "1  Studio 22a\\nLynne terrace\\nMcCarthymouth\\nTF0 9GH  United Kingdom   \n",
      "2                 92 Ann drive\\nJoanborough\\nSK0 6LR  United Kingdom   \n",
      "3             19 Robinson meadow\\nNew Tracy\\nW22 2QG  United Kingdom   \n",
      "4              3 White pass\\nHunterborough\\nNN96 4UE  United Kingdom   \n",
      "\n",
      "  country_code       phone_number   join_date  \\\n",
      "0           DE   +49(0) 047905356  2018-10-10   \n",
      "1           GB    (0161) 496 0674  2001-12-20   \n",
      "2           GB  +44(0)121 4960340  2016-12-16   \n",
      "3           GB    (0306) 999 0871  2004-02-23   \n",
      "4           GB      0121 496 0225  2006-09-01   \n",
      "\n",
      "                              user_uuid  \n",
      "0  93caf182-e4e9-4c6e-bebb-60a1a9dcf9b8  \n",
      "1  8fe96c3a-d62d-4eb5-b313-cf12d9126a49  \n",
      "2  fc461df4-b919-48b2-909e-55c95a03fe6b  \n",
      "3  6104719f-ef14-4b09-bf04-fb0c4620acb0  \n",
      "4  9523a6d3-b2dd-4670-a51a-36aebc89f579  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15320 entries, 0 to 15319\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   index          15320 non-null  int64 \n",
      " 1   first_name     15320 non-null  object\n",
      " 2   last_name      15320 non-null  object\n",
      " 3   date_of_birth  15320 non-null  object\n",
      " 4   company        15320 non-null  object\n",
      " 5   email_address  15320 non-null  object\n",
      " 6   address        15320 non-null  object\n",
      " 7   country        15320 non-null  object\n",
      " 8   country_code   15320 non-null  object\n",
      " 9   phone_number   15320 non-null  object\n",
      " 10  join_date      15320 non-null  object\n",
      " 11  user_uuid      15320 non-null  object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 1.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "user_table_rds = 'legacy_users'\n",
    "\n",
    "extractor_rds = DataExtractor(connection_rds)\n",
    "\n",
    "user_df_rds = extractor_rds.read_rds_table(user_table_rds)\n",
    "print(user_df_rds.head(5))\n",
    "print(user_df_rds.info())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for Null values:\n",
      "index            0.0\n",
      "first_name       0.0\n",
      "last_name        0.0\n",
      "date_of_birth    0.0\n",
      "company          0.0\n",
      "email_address    0.0\n",
      "address          0.0\n",
      "country          0.0\n",
      "country_code     0.0\n",
      "phone_number     0.0\n",
      "join_date        0.0\n",
      "user_uuid        0.0\n",
      "dtype: float64\n",
      "Deleting rows with more than 4 Null values\n",
      "       index first_name last_name date_of_birth                       company  \\\n",
      "0          0   Sigfried     Noack    1990-09-30            Heydrich Junitz KG   \n",
      "1          1        Guy     Allen    1940-12-01                       Fox Ltd   \n",
      "2          2      Harry  Lawrence    1995-08-02     Johnson, Jones and Harris   \n",
      "3          3     Darren   Hussain    1972-09-23                   Wheeler LLC   \n",
      "4          4      Garry     Stone    1952-12-20                    Warner Inc   \n",
      "...      ...        ...       ...           ...                           ...   \n",
      "15315  14913    Stephen   Jenkins    1943-08-09  Thornton, Carroll and Newman   \n",
      "15316  14994    Stephen     Smith    1948-08-20               Robinson-Harris   \n",
      "15317  15012    Stephen  Losekann    1940-10-09                       Rosenow   \n",
      "15318  15269    Stephen    Rivera    1952-06-04         Taylor, Fry and Jones   \n",
      "15319   1249    Stephen    Duncan    1994-03-27    Phillips, Brown and Powell   \n",
      "\n",
      "                      email_address  \\\n",
      "0                 rudi79@winkler.de   \n",
      "1      rhodesclifford@henderson.com   \n",
      "2      glen98@bryant-marshall.co.uk   \n",
      "3        daniellebryan@thompson.org   \n",
      "4           billy14@long-warren.com   \n",
      "...                             ...   \n",
      "15315           s.jenkins@smith.com   \n",
      "15316             s.smith@smith.com   \n",
      "15317          s.losekann@smith.com   \n",
      "15318            s.rivera@smith.com   \n",
      "15319            s.duncan@smith.com   \n",
      "\n",
      "                                                 address         country  \\\n",
      "0                           Zimmerstr. 1/0\\n59015 Gießen         Germany   \n",
      "1      Studio 22a\\nLynne terrace\\nMcCarthymouth\\nTF0 9GH  United Kingdom   \n",
      "2                     92 Ann drive\\nJoanborough\\nSK0 6LR  United Kingdom   \n",
      "3                 19 Robinson meadow\\nNew Tracy\\nW22 2QG  United Kingdom   \n",
      "4                  3 White pass\\nHunterborough\\nNN96 4UE  United Kingdom   \n",
      "...                                                  ...             ...   \n",
      "15315     Studio 41I\\nJones lodge\\nOliviaborough\\nE8 3DU  United Kingdom   \n",
      "15316              530 Young parkway\\nMillsfurt\\nL4G 7NX  United Kingdom   \n",
      "15317  Viviane-Fritsch-Straße 3/5\\n15064 Bad Liebenwerda         Germany   \n",
      "15318   660 Ross Falls Suite 357\\nAnthonymouth, MA 09610   United States   \n",
      "15319     Studio 4\\nHancock road\\nPhillipsview\\nST1X 3XB  United Kingdom   \n",
      "\n",
      "      country_code       phone_number   join_date  \\\n",
      "0               DE   +49(0) 047905356  2018-10-10   \n",
      "1               GB    (0161) 496 0674  2001-12-20   \n",
      "2               GB  +44(0)121 4960340  2016-12-16   \n",
      "3               GB    (0306) 999 0871  2004-02-23   \n",
      "4               GB      0121 496 0225  2006-09-01   \n",
      "...            ...                ...         ...   \n",
      "15315           GB    +44(0)292018946  2016-04-15   \n",
      "15316           GB   +44(0)1144960977  2020-07-20   \n",
      "15317           DE        02984 08192  2021-03-07   \n",
      "15318           US       239.711.3836  2011-01-03   \n",
      "15319           GB   +44(0)1314960870  2015-08-28   \n",
      "\n",
      "                                  user_uuid  \n",
      "0      93caf182-e4e9-4c6e-bebb-60a1a9dcf9b8  \n",
      "1      8fe96c3a-d62d-4eb5-b313-cf12d9126a49  \n",
      "2      fc461df4-b919-48b2-909e-55c95a03fe6b  \n",
      "3      6104719f-ef14-4b09-bf04-fb0c4620acb0  \n",
      "4      9523a6d3-b2dd-4670-a51a-36aebc89f579  \n",
      "...                                     ...  \n",
      "15315  2bd3a12f-a92d-4cdd-b99c-fc70572db302  \n",
      "15316  d234c04b-c07c-46a5-a902-526f91478ecc  \n",
      "15317  1a0a8b7b-7c17-42d8-a946-8a85d5495651  \n",
      "15318  187fe06e-bd5f-4381-af2f-d7ac37ca7572  \n",
      "15319  0589bbca-1d58-4b1f-9d0a-04ed4c57aaa1  \n",
      "\n",
      "[15320 rows x 12 columns]\n",
      "Looking for duplicates:\n",
      "0        False\n",
      "1        False\n",
      "2        False\n",
      "3        False\n",
      "4        False\n",
      "         ...  \n",
      "15315    False\n",
      "15316    False\n",
      "15317    False\n",
      "15318    False\n",
      "15319    False\n",
      "Length: 15320, dtype: bool\n",
      "checking data types for each columns\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 15320 entries, 0 to 15319\n",
      "Data columns (total 12 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   index          15320 non-null  int64 \n",
      " 1   first_name     15320 non-null  object\n",
      " 2   last_name      15320 non-null  object\n",
      " 3   date_of_birth  15320 non-null  object\n",
      " 4   company        15320 non-null  object\n",
      " 5   email_address  15320 non-null  object\n",
      " 6   address        15320 non-null  object\n",
      " 7   country        15320 non-null  object\n",
      " 8   country_code   15320 non-null  object\n",
      " 9   phone_number   15320 non-null  object\n",
      " 10  join_date      15320 non-null  object\n",
      " 11  user_uuid      15320 non-null  object\n",
      "dtypes: int64(1), object(11)\n",
      "memory usage: 1.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clean_data_rds = DataCleaning()\n",
    "clean_df_rds = clean_data_rds.clean_user_data(user_df_rds)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Loading the data\n",
    "#### uploading the cleaned dataframe into the local database\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data uploaded successfully to dim_users table.\n"
     ]
    }
   ],
   "source": [
    "# Connect with the local database\n",
    "\n",
    "\n",
    "\n",
    "#load clean rds dataframe into local database with a new table\n",
    "uploader.upload_to_db(uploading, clean_df_rds, 'dim_users')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF data: ETL\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.Getting the data from PDF & load in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "connector_pdf = DatabaseConnector()\n",
    "extractor_pdf = DataExtractor(connector_pdf)\n",
    "\n",
    "link = \"https://data-handling-public.s3.eu-west-1.amazonaws.com/card_details.pdf\"\n",
    "extraction_pdf = extractor_pdf.retrieve_pdf_data(link)\n",
    "print(extraction_pdf.head(5))\n",
    "print(extraction_pdf.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.Clean the pdf df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_pdf = DataCleaning()\n",
    "\n",
    "clean_df_pdf =clean_pdf.clean_card_data(extraction_pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. load into db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "uploader.upload_to_db(uploading, clean_df_pdf, 'dim_card_details')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PDF data: API\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Getting Data from API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'x-api-key': 'yFBQbwXe9J3sd6zWVAMrK6lcxxr0q1lr2PT6DDMX'\n",
    "}\n",
    "\n",
    "number_of_stores_endpoint = 'https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/number_stores'\n",
    "\n",
    "connector_api = DatabaseConnector()\n",
    "\n",
    "extractor_api = DataExtractor(connector_api)\n",
    "\n",
    "number_of_stores = extractor_api.list_number_of_stores(number_of_stores_endpoint, headers)\n",
    "print(f\"Number of stores: {number_of_stores}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extracting the table to a pandas DataFrame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieve_store_endpoint = 'https://aqj7u5id95.execute-api.eu-west-1.amazonaws.com/prod/store_details/2'\n",
    "\n",
    "stores_df = extractor_api.retrieve_stores_data(retrieve_store_endpoint, headers, 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.Cleaning data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clean_stores_api = DataCleaning()\n",
    "clean_storesdf_api = clean_stores_api.called_clean_store_data(stores_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import data_extraction, data_cleaning,database_utils\n",
    "importlib.reload(data_extraction)\n",
    "importlib.reload(database_utils)\n",
    "importlib.reload(data_cleaning)\n",
    "from data_extraction import DataExtractor\n",
    "from database_utils import DatabaseConnector\n",
    "from data_cleaning import DataCleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Loading the data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploader.upload_to_db(uploading, clean_storesdf_api, 'dim_store_details')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## S3 data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Getting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "connector_s3 = DatabaseConnector()\n",
    "extractor_s3 = DataExtractor(connector_s3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Putting into pd df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0                                      product_name  \\\n",
      "0            0       FurReal Dazzlin' Dimples My Playful Dolphin   \n",
      "1            1               Tiffany's World Day Out At The Park   \n",
      "2            2               Tiffany's World Pups Picnic Playset   \n",
      "3            3          Tiffany's World Wildlife Park Adventures   \n",
      "4            4                           Cosatto Cosy Dolls Pram   \n",
      "5            5                      Cocomelon Magnetic Scribbler   \n",
      "6            6                           Peppa Pig House Felties   \n",
      "7            7                         Paw Patrol Walkie Talkies   \n",
      "8            8                       Peppa Pig 3D Walkie Talkies   \n",
      "9            9              Disney Encanto Magical Casa Madrigal   \n",
      "10          10                     Disney Encanto Mirabel's Room   \n",
      "11          11              Disney Encanto Isabela's Garden Room   \n",
      "12          12               Disney Encanto Antonio's Tree House   \n",
      "13          13                            Tie-Dye Slime Mega Set   \n",
      "14          14                     Paw Patrol Magnetic Scribbler   \n",
      "15          15                      Light Up Secret Hideout Tent   \n",
      "16          16                        Light Up Army Hideout Tent   \n",
      "17          17               Tiffany's World Fabulous Food Truck   \n",
      "18          18  Treasure X Dino Gold Pterodactyl Dino Dissection   \n",
      "19          19                                  My Crawling Bear   \n",
      "\n",
      "   product_price   weight        category            EAN  date_added  \\\n",
      "0         £39.99    1.6kg  toys-and-games  7425710935115  2005-12-02   \n",
      "1         £12.99   0.48kg  toys-and-games   487128731892  2006-01-09   \n",
      "2          £7.00     590g  toys-and-games  1945816904649  1997-03-29   \n",
      "3         £12.99     540g  toys-and-games  1569790890899  2013-03-20   \n",
      "4         £30.00   1.91kg  toys-and-games  7142740213920  2007-12-23   \n",
      "5         £12.99   0.91kg  toys-and-games  9022505507373  2007-02-07   \n",
      "6          £7.00   0.46kg  toys-and-games  5997977455405  2009-01-24   \n",
      "7         £12.99   0.38kg  toys-and-games    58555395171  2013-08-13   \n",
      "8         £12.99   0.38kg  toys-and-games  9155372675699  2005-05-26   \n",
      "9         £89.99  8.981kg  toys-and-games  2740880244498  2003-08-05   \n",
      "10        £24.99  1.478kg  toys-and-games  9821316839389  2013-09-20   \n",
      "11        £24.99     1.2g  toys-and-games  9644535434254  2019-08-14   \n",
      "12        £24.99     1.2g  toys-and-games  2421335285067  2019-04-13   \n",
      "13        £12.99   0.66kg  toys-and-games  9526390929079  2014-05-20   \n",
      "14        £12.99   0.91kg  toys-and-games  7886193859037  2003-12-21   \n",
      "15        £22.00    1.8kg  toys-and-games  8231049510317  2019-02-17   \n",
      "16        £22.00    1.9kg  toys-and-games  9963791896324  2007-02-13   \n",
      "17        £20.00  1.725kg  toys-and-games  5348126886814  1996-08-19   \n",
      "18        £16.99   0.54kg  toys-and-games  1156454414579  2003-11-12   \n",
      "19        £12.99  0.322kg  toys-and-games   159264905771  2000-04-19   \n",
      "\n",
      "                                    uuid          removed product_code  \n",
      "0   83dc0a69-f96f-4c34-bcb7-928acae19a94  Still_avaliable  R7-3126933h  \n",
      "1   712254d7-aea7-4310-aff8-8bcdd0aec7ff  Still_avaliable  C2-7287916l  \n",
      "2   b089ef6f-b628-4e37-811d-fffe0102ba64  Still_avaliable  S7-1175877v  \n",
      "3   d55de422-8b98-47d6-9991-e4bc4c5c0cb0          Removed  D8-8421505n  \n",
      "4   7945b657-cb02-4cc5-96cf-f65ed0a8f235  Still_avaliable  B6-2596063a  \n",
      "5   cdd568e3-9657-412b-b3a6-52f6adff966b  Still_avaliable  g3-7974400s  \n",
      "6   58112753-a53f-4696-ab8a-7186c7e4a57e  Still_avaliable  U3-5148457q  \n",
      "7   797d133a-0989-4707-914d-7c043bcbbd86  Still_avaliable  q8-5387483Z  \n",
      "8   a6c23718-0e25-4419-8018-600c44e5e3df  Still_avaliable  i4-2651057I  \n",
      "9   2e78e9a4-2b77-4b59-95e5-d60ee01ef183  Still_avaliable  b6-6234052g  \n",
      "10  baa31d12-ad99-4442-b663-bd8a525c1c7a  Still_avaliable   g5-411324A  \n",
      "11  e36989b3-7371-40ea-80b8-c23ba1a6869f  Still_avaliable  S6-3678717g  \n",
      "12  d3ed56bc-533e-42fe-839a-ba880bda5714  Still_avaliable  Z2-0851042W  \n",
      "13  44d36b71-477e-44f9-8dbc-e771a1bfbc11          Removed  t5-7763922W  \n",
      "14  85610de0-f2b0-4613-9b51-343875197314  Still_avaliable  Z8-4148279f  \n",
      "15  1f692916-439d-41c4-a524-b51bf6088e1d  Still_avaliable  l4-0484985I  \n",
      "16  41861b23-4675-4cd5-90b1-03a24afad922  Still_avaliable  P1-5362711n  \n",
      "17  245a17fd-7e6c-43b2-9708-5bc87f51329c          Removed  v7-6917295v  \n",
      "18  8a6c33e3-0278-4e92-b434-6664d3db6d8b  Still_avaliable  D0-3518057L  \n",
      "19  c5189222-d270-44c5-8b9b-5598378c7dcc  Still_avaliable    w1-22434p  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1853 entries, 0 to 1852\n",
      "Data columns (total 10 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   Unnamed: 0     1853 non-null   int64 \n",
      " 1   product_name   1849 non-null   object\n",
      " 2   product_price  1849 non-null   object\n",
      " 3   weight         1849 non-null   object\n",
      " 4   category       1849 non-null   object\n",
      " 5   EAN            1849 non-null   object\n",
      " 6   date_added     1849 non-null   object\n",
      " 7   uuid           1849 non-null   object\n",
      " 8   removed        1849 non-null   object\n",
      " 9   product_code   1849 non-null   object\n",
      "dtypes: int64(1), object(9)\n",
      "memory usage: 144.9+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "bucket = 'data-handling-public'\n",
    "object_key = \"products.csv\"\n",
    "pathway = '/Users/student/AICORE/AWS/Project_3/products.csv'\n",
    "\n",
    "extraction_s3 = extractor_s3.extract_from_s3(bucket, object_key, pathway)\n",
    "print(extraction_s3.head(20))\n",
    "print(extraction_s3.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Cleaning data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m clean_s3 \u001b[38;5;241m=\u001b[39m DataCleaning()\n\u001b[0;32m----> 3\u001b[0m clean_s3 \u001b[38;5;241m=\u001b[39m\u001b[43mclean_s3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_product_weights\u001b[49m\u001b[43m(\u001b[49m\u001b[43mextraction_s3\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/AICORE/AWS/Project_3/data_cleaning.py:81\u001b[0m, in \u001b[0;36mDataCleaning.convert_product_weights\u001b[0;34m(self, csv_df)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     79\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(weight) \n\u001b[0;32m---> 81\u001b[0m csv_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mcsv_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mweight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert_weight\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28mprint\u001b[39m(csv_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39msum())\n\u001b[1;32m     83\u001b[0m csv_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfillna(csv_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mweight\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean(), inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/series.py:4924\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[1;32m   4789\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[1;32m   4790\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   4791\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4796\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   4797\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m   4798\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4799\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4800\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4915\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4916\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   4917\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mSeriesApply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4918\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4919\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4920\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconvert_dtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4921\u001b[0m \u001b[43m        \u001b[49m\u001b[43mby_row\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mby_row\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4922\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4923\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m-> 4924\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/apply.py:1427\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1424\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[1;32m   1426\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[0;32m-> 1427\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/apply.py:1507\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1501\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[1;32m   1505\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[1;32m   1506\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1507\u001b[0m mapped \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_map_values\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1508\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmapper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcurried\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert_dtype\u001b[49m\n\u001b[1;32m   1509\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1512\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1513\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1514\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[0;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[1;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[0;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43malgorithms\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_action\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna_action\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.12/site-packages/pandas/core/algorithms.py:1743\u001b[0m, in \u001b[0;36mmap_array\u001b[0;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[1;32m   1741\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   1742\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1743\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap_infer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmapper\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[1;32m   1746\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[1;32m   1747\u001b[0m     )\n",
      "File \u001b[0;32mlib.pyx:2972\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/AICORE/AWS/Project_3/data_cleaning.py:79\u001b[0m, in \u001b[0;36mDataCleaning.convert_product_weights.<locals>.convert_weight\u001b[0;34m(weight)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(con_weight)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 79\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "clean_s3 = DataCleaning()\n",
    "\n",
    "clean_s3 =clean_s3.convert_product_weights(extraction_s3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Loading into local db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uploader.upload_to_db(uploading, clean_api, 'dim_products')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
